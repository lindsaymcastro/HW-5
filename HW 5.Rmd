---
title: "Homework 5"
output:
  html_document:
    toc: yes
    toc_float: yes
    code_folding: show
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE)
```


## Elastic Net Tuning 
```{r, message=FALSE}
library(tidymodels)
library(tidyverse)
library(ISLR) 
library(ISLR2) 
library(discrim)
library(poissonreg)
library(corrr)
library(corrplot)
library(klaR) 
library(pROC)
library(glmnet)
library(dplyr)
tidymodels_prefer()

```


```{r}
pokemon <- read.csv(file = "homework-5/data/pokemon.csv")
```


### Exercise 1 
```{r}
library(janitor)

pokemon <- clean_names(pokemon)
head(pokemon)
```

After using the clean_names() function, it changed the variable names to all appear as lowercase and replaced the periods with '_' which also
represent spaces in the names themselves. clean_names() is useful because it allows all the variable names to follow the same format to avoid
confusion especially when they are going to be called later on. 



### Exercise 2 
```{r}
type1bar <- ggplot(data = pokemon, aes(x = type_1)) +
  geom_bar(stat = "count", width = 0.7, fill = "steelblue")+
  theme_minimal()+
  geom_text(stat = 'count', aes(label = ..count..), hjust = .4, vjust = -1)+
  labs(title = "Type 1 Classes", x = "Classes", y = "Count")
type1bar

pokemon <- pokemon %>%
  filter(type_1 == "Bug" | type_1 == "Fire" | type_1 == "Grass" | type_1 ==  "Normal" | type_1 ==  "Water" | type_1 == "Psychic")


pokemon$type_1 <- as.factor(pokemon$type_1)
pokemon$legendary <- as.factor(pokemon$legendary)
pokemon$generation <- as.factor(pokemon$generation)
```

There are 18 classes of the outcomes for type_1. There are a couple of Pokemon types that do have very few Pokemon. Those are Flying, Fairy, Ice, and Fighting because the have less than 30. 


### Exercise 3 
```{r}
set.seed(0714)

# Initial Split
pokemon_split <- initial_split(pokemon, strata = type_1, prop = 0.7)
pokemon_split

#Separate into training and testing
pokemon_train <- training(pokemon_split)
pokemon_test <- testing(pokemon_split)

# Verify correct # of observations
dim(pokemon_train)
dim(pokemon_test)

# V-fold cross validation
pokemon_fold <- vfold_cv(pokemon_train, strata = type_1, v = 5)
```


### Exercise 4 
```{r}
pokemon_recipe <- recipe(type_1 ~ legendary + generation + sp_atk +
                           attack + speed + defense + hp + sp_def,
                         data = pokemon_train) %>%
  step_dummy(c(legendary, generation)) %>%
  step_normalize(all_predictors())

```


### Exercise 5 
```{r}
pokemon_mod <- 
  multinom_reg(penalty = tune(), mixture = tune()) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

pokemon_wf <- workflow() %>%
  add_recipe(pokemon_recipe) %>%
  add_model(pokemon_mod)

reg_grid <- grid_regular(penalty(range = c(-5, 5)), 
                         mixture(range = c(0, 1)), 
                         levels = 10)

```
There will be 500 models fitted because the range for penalty is 10 across 10 levels, for 5 folds (all multiplied is 500)


### Exercise 6 
```{r, message=FALSE}
pokemon_res <- tune_grid(
  pokemon_wf,
  resamples = pokemon_fold,
  grid = reg_grid,
  control = control_grid(verbose = TRUE)
)

autoplot(pokemon_res)
```

Smaller values of penalty produce better accuracy and ROC AUC, however for mixture the values differ from 0.444 to 0.777 for better accuracy and ROC 
AUC respectively.


### Exercise 7 
```{r}
#Choose model with optimal roc_auc
best <- select_best(pokemon_res, metric = "roc_auc")
best

#Fit model to training set
pokemon_final <- finalize_workflow(pokemon_wf, best)
pokemon_final_fit <- fit(pokemon_final, data = pokemon_train)

#Evaluate training set
multi_metric <- metric_set(accuracy, sensitivity, specificity)
augment(pokemon_final_fit, new_data = pokemon_train) %>%
  multi_metric(truth = type_1, estimate = .pred_class)

#Evaluate testing set
augment(pokemon_final_fit, new_data = pokemon_test) %>%
  multi_metric(truth = type_1, estimate = .pred_class)
  
```


### Exercise 8 
```{r}
library(yardstick)
# Overall ROC AUC
augment(pokemon_final_fit, new_data = pokemon_test) %>%
  roc_auc(truth = type_1, .pred_Bug, .pred_Fire, .pred_Grass, .pred_Normal, .pred_Psychic, .pred_Water)

# Plots
augment(pokemon_final_fit, new_data = pokemon_test) %>%
  roc_curve(truth = type_1, .pred_Bug, .pred_Fire, .pred_Grass, .pred_Normal, .pred_Psychic, .pred_Water) %>%
  autoplot()

# Heatmap of Confusion Matrix
augment(pokemon_final_fit, new_data = pokemon_test) %>%
  conf_mat(truth = type_1, estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```


Based off the heatmap, the model does the best at predicting Normal and Water types, and its the worst at predicting 
Fire, and Grass. Based off the plots for the different ROC curves, Normal types makes sense on why it is the best at 
predicting it correctly, however it does not make much sense for the Water type since the ROC curve seems to be low. It 
also seems that the model overpredicts the type Water for all the other types as well. 
















